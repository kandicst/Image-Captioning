{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "from data_preprocessing import *\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data_train_dir = 'extracted_data/train/'\n",
    "extracted_data_test_dir = 'extracted_data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file, 'r') as f1:\n",
    "        return json.loads(f1.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions = load_json(extracted_data_train_dir + 'captions.json')\n",
    "train_image_paths = load_json(extracted_data_train_dir + 'image_paths.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> A bathroom with a TV near the mirror <END>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mscoco/train/img/COCO_train2014_000000028149'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_captions = [x[8:] for x in train_captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mscoco/train/img/COCO_train2014_000000318556 <START> A very clean and well decorated empty bathroom <END>\n"
     ]
    }
   ],
   "source": [
    "print(train_image_paths[0], train_captions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = Vocabulary(train_captions, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfdx = Vocabulary(train_captions, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 145, 430, 10, 667, 450, 237, 35, 2]\n",
      "<start> a very clean and well decorated empty bathroom <end>\n",
      "<START> A very clean and well decorated empty bathroom <END>\n"
     ]
    }
   ],
   "source": [
    "print(train_vocab.encoded_captions[0])\n",
    "print(train_vocab.decode_sentence(train_vocab.encoded_captions[0]))\n",
    "print(train_captions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoded captions for each caption in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 145, 430, 10, 667, 450, 237, 35, 2]]\n",
      "<start> a very clean and well decorated empty bathroom <end>\n",
      "['<START> A very clean and well decorated empty bathroom <END>']\n"
     ]
    }
   ],
   "source": [
    "encoded_captions_train = [train_vocab.encode_sentence(x) for x in train_captions]\n",
    "\n",
    "print(encoded_captions_train[:1])\n",
    "print(train_vocab.decode_sentence(encoded_captions_train[0]))\n",
    "print(train_captions[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_captions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from MyDataset import MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249454\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "wat = [torch.tensor(x[1:], dtype=torch.int16) for x in train_vocab.encoded_captions]\n",
    "# wat = [torch.tensor(x, dtype=torch.int16) for x in train_vocab.encoded_captions]\n",
    "padded = pad_sequence(wat).permute(1, 0)\n",
    "print(len(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 35, 9, 4, 397, 31, 5, 140, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_captions_train[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 35, 9, 4, 397, 31, 5, 140, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab.encoded_captions[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([249454, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4, 145, 430,  10, 667, 450, 237,  35,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0], dtype=torch.int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(enc_captions=padded,\n",
    "                    image_paths=train_image_paths,\n",
    "                   data_dir=extracted_data_train_dir + 'vecs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small dataste\n",
    "dataset = MyDataset(enc_captions=padded[:256],\n",
    "                    image_paths=train_image_paths[:256],\n",
    "                   data_dir=extracted_data_train_dir + 'vecs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2048])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=256, \n",
    "                         num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 64, 2048])\n",
      "torch.Size([50])\n",
      "[4, 145, 430, 10, 667, 450, 237, 35, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "a very clean and well decorated empty bathroom <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(dataloader):\n",
    "    imgs, labels = data[0], data[1]\n",
    "    print(idx, imgs.shape)\n",
    "    print(labels[0].shape)\n",
    "    print(labels[0].tolist())\n",
    "    print(train_vocab.decode_sentence(labels[0].tolist()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.Encoder import Encoder\n",
    "from layers.Decoder import Decoder\n",
    "from layers.Attention import Attention\n",
    "from layers.End2End import End2End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC_EMB_DIM = 512\n",
    "ENC_INPUT = 2048\n",
    "ENC_OUTPUT = 256 \n",
    "DEC_HID_DIM = 512\n",
    "DEC_OUTPUT = 512\n",
    "ATTN_DIM = 512\n",
    "EMB_DIM = 256\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,128,201 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = End2End(ENC_INPUT, ENC_OUTPUT, DEC_HID_DIM, DEC_OUTPUT,\n",
    "               EMB_DIM, ATTN_DIM, train_vocab, criterion, device)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []\n",
    "\n",
    "def train_step(batch, captions):\n",
    "    \n",
    "    batch_size = captions.shape[0]\n",
    "    caption_length = captions.shape[1]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out, loss = model(batch, captions)\n",
    "#     ww = out[0]\n",
    "#     ww = torch.max(ww, dim=1)[1]\n",
    "#     print(train_vocab.decode_sentence(ww.tolist()))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss = loss / int(caption_length)\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.2354\n",
      "Epoch 1 Loss 3.235376\n",
      "Time taken for 1 epoch 3.7582223415374756 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.2176\n",
      "Epoch 2 Loss 3.217591\n",
      "Time taken for 1 epoch 3.65273118019104 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.1994\n",
      "Epoch 3 Loss 3.199425\n",
      "Time taken for 1 epoch 3.5865771770477295 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 3.1799\n",
      "Epoch 4 Loss 3.179932\n",
      "Time taken for 1 epoch 3.5758872032165527 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.1583\n",
      "Epoch 5 Loss 3.158252\n",
      "Time taken for 1 epoch 3.4938254356384277 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.1336\n",
      "Epoch 6 Loss 3.133575\n",
      "Time taken for 1 epoch 3.5477232933044434 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.1051\n",
      "Epoch 7 Loss 3.105094\n",
      "Time taken for 1 epoch 3.482170820236206 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.0720\n",
      "Epoch 8 Loss 3.072006\n",
      "Time taken for 1 epoch 3.5930233001708984 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.0335\n",
      "Epoch 9 Loss 3.033530\n",
      "Time taken for 1 epoch 3.5585713386535645 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 2.9889\n",
      "Epoch 10 Loss 2.988914\n",
      "Time taken for 1 epoch 3.490849256515503 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.9375\n",
      "Epoch 11 Loss 2.937479\n",
      "Time taken for 1 epoch 3.5741770267486572 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 2.8787\n",
      "Epoch 12 Loss 2.878673\n",
      "Time taken for 1 epoch 3.513665199279785 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 2.8122\n",
      "Epoch 13 Loss 2.812171\n",
      "Time taken for 1 epoch 3.5037448406219482 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.7380\n",
      "Epoch 14 Loss 2.738003\n",
      "Time taken for 1 epoch 3.5019607543945312 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.6568\n",
      "Epoch 15 Loss 2.656825\n",
      "Time taken for 1 epoch 3.5196173191070557 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.5704\n",
      "Epoch 16 Loss 2.570384\n",
      "Time taken for 1 epoch 3.4819202423095703 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.4825\n",
      "Epoch 17 Loss 2.482532\n",
      "Time taken for 1 epoch 3.532536745071411 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.4011\n",
      "Epoch 18 Loss 2.401080\n",
      "Time taken for 1 epoch 3.535005569458008 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.3400\n",
      "Epoch 19 Loss 2.339959\n",
      "Time taken for 1 epoch 3.525947332382202 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.3141\n",
      "Epoch 20 Loss 2.314054\n",
      "Time taken for 1 epoch 3.534000873565674 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.3116\n",
      "Epoch 21 Loss 2.311604\n",
      "Time taken for 1 epoch 3.4710092544555664 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.2975\n",
      "Epoch 22 Loss 2.297458\n",
      "Time taken for 1 epoch 3.481792449951172 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.2571\n",
      "Epoch 23 Loss 2.257103\n",
      "Time taken for 1 epoch 3.4878721237182617 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 2.2019\n",
      "Epoch 24 Loss 2.201944\n",
      "Time taken for 1 epoch 3.4958086013793945 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 2.1463\n",
      "Epoch 25 Loss 2.146341\n",
      "Time taken for 1 epoch 3.5321898460388184 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 2.0981\n",
      "Epoch 26 Loss 2.098053\n",
      "Time taken for 1 epoch 3.5077123641967773 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 2.0609\n",
      "Epoch 27 Loss 2.060918\n",
      "Time taken for 1 epoch 3.5796329975128174 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 2.0337\n",
      "Epoch 28 Loss 2.033674\n",
      "Time taken for 1 epoch 3.510193109512329 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 2.0105\n",
      "Epoch 29 Loss 2.010520\n",
      "Time taken for 1 epoch 3.5154049396514893 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 1.9865\n",
      "Epoch 30 Loss 1.986536\n",
      "Time taken for 1 epoch 3.4938242435455322 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 1.9594\n",
      "Epoch 31 Loss 1.959382\n",
      "Time taken for 1 epoch 3.508209466934204 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 1.9300\n",
      "Epoch 32 Loss 1.929954\n",
      "Time taken for 1 epoch 3.5786406993865967 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 1.9010\n",
      "Epoch 33 Loss 1.901015\n",
      "Time taken for 1 epoch 3.485891103744507 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 1.8749\n",
      "Epoch 34 Loss 1.874889\n",
      "Time taken for 1 epoch 3.495311737060547 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 1.8524\n",
      "Epoch 35 Loss 1.852420\n",
      "Time taken for 1 epoch 3.4977922439575195 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 1.8325\n",
      "Epoch 36 Loss 1.832462\n",
      "Time taken for 1 epoch 3.5441813468933105 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 1.8131\n",
      "Epoch 37 Loss 1.813056\n",
      "Time taken for 1 epoch 3.5146572589874268 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 1.7926\n",
      "Epoch 38 Loss 1.792608\n",
      "Time taken for 1 epoch 3.5588009357452393 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 1.7709\n",
      "Epoch 39 Loss 1.770921\n",
      "Time taken for 1 epoch 3.5292868614196777 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 1.7494\n",
      "Epoch 40 Loss 1.749380\n",
      "Time taken for 1 epoch 3.5161445140838623 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 1.7280\n",
      "Epoch 41 Loss 1.727965\n",
      "Time taken for 1 epoch 3.4881579875946045 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 1.7077\n",
      "Epoch 42 Loss 1.707668\n",
      "Time taken for 1 epoch 3.5677297115325928 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 1.6889\n",
      "Epoch 43 Loss 1.688944\n",
      "Time taken for 1 epoch 3.5607047080993652 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 1.6725\n",
      "Epoch 44 Loss 1.672482\n",
      "Time taken for 1 epoch 3.4839041233062744 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 1.6582\n",
      "Epoch 45 Loss 1.658230\n",
      "Time taken for 1 epoch 3.489360809326172 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 1.6453\n",
      "Epoch 46 Loss 1.645272\n",
      "Time taken for 1 epoch 3.5746095180511475 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 1.6329\n",
      "Epoch 47 Loss 1.632904\n",
      "Time taken for 1 epoch 3.5111851692199707 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 1.6208\n",
      "Epoch 48 Loss 1.620834\n",
      "Time taken for 1 epoch 3.5202455520629883 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 1.6087\n",
      "Epoch 49 Loss 1.608744\n",
      "Time taken for 1 epoch 3.4824161529541016 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 1.5967\n",
      "Epoch 50 Loss 1.596703\n",
      "Time taken for 1 epoch 3.4779515266418457 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 1.5848\n",
      "Epoch 51 Loss 1.584751\n",
      "Time taken for 1 epoch 3.5116915702819824 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 1.5733\n",
      "Epoch 52 Loss 1.573252\n",
      "Time taken for 1 epoch 3.5801291465759277 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 1.5624\n",
      "Epoch 53 Loss 1.562360\n",
      "Time taken for 1 epoch 3.503249168395996 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 1.5528\n",
      "Epoch 54 Loss 1.552831\n",
      "Time taken for 1 epoch 3.5253047943115234 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 1.5441\n",
      "Epoch 55 Loss 1.544084\n",
      "Time taken for 1 epoch 3.4978549480438232 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 1.5358\n",
      "Epoch 56 Loss 1.535778\n",
      "Time taken for 1 epoch 3.4657182693481445 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 1.5283\n",
      "Epoch 57 Loss 1.528261\n",
      "Time taken for 1 epoch 3.503659963607788 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 1.5217\n",
      "Epoch 58 Loss 1.521742\n",
      "Time taken for 1 epoch 3.5112557411193848 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 1.5157\n",
      "Epoch 59 Loss 1.515727\n",
      "Time taken for 1 epoch 3.493607521057129 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 1.5098\n",
      "Epoch 60 Loss 1.509764\n",
      "Time taken for 1 epoch 3.5796329975128174 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 1.5042\n",
      "Epoch 61 Loss 1.504155\n",
      "Time taken for 1 epoch 3.558947801589966 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 1.4989\n",
      "Epoch 62 Loss 1.498909\n",
      "Time taken for 1 epoch 3.5804800987243652 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 1.4939\n",
      "Epoch 63 Loss 1.493939\n",
      "Time taken for 1 epoch 3.560141086578369 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 1.4892\n",
      "Epoch 64 Loss 1.489191\n",
      "Time taken for 1 epoch 3.5449047088623047 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 1.4847\n",
      "Epoch 65 Loss 1.484664\n",
      "Time taken for 1 epoch 3.5999929904937744 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 1.4809\n",
      "Epoch 66 Loss 1.480941\n",
      "Time taken for 1 epoch 3.5297162532806396 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 1.4772\n",
      "Epoch 67 Loss 1.477173\n",
      "Time taken for 1 epoch 3.585329055786133 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 1.4736\n",
      "Epoch 68 Loss 1.473595\n",
      "Time taken for 1 epoch 3.6401474475860596 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 1.4702\n",
      "Epoch 69 Loss 1.470166\n",
      "Time taken for 1 epoch 3.4897584915161133 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 1.4671\n",
      "Epoch 70 Loss 1.467067\n",
      "Time taken for 1 epoch 3.4839749336242676 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 1.4637\n",
      "Epoch 71 Loss 1.463736\n",
      "Time taken for 1 epoch 3.520155906677246 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 1.4603\n",
      "Epoch 72 Loss 1.460257\n",
      "Time taken for 1 epoch 3.5092005729675293 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 1.4568\n",
      "Epoch 73 Loss 1.456806\n",
      "Time taken for 1 epoch 3.615344524383545 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 1.4533\n",
      "Epoch 74 Loss 1.453254\n",
      "Time taken for 1 epoch 3.4968101978302 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 1.4498\n",
      "Epoch 75 Loss 1.449849\n",
      "Time taken for 1 epoch 3.5025634765625 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 1.4466\n",
      "Epoch 76 Loss 1.446599\n",
      "Time taken for 1 epoch 3.529041051864624 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 1.4432\n",
      "Epoch 77 Loss 1.443156\n",
      "Time taken for 1 epoch 3.579137086868286 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 1.4398\n",
      "Epoch 78 Loss 1.439842\n",
      "Time taken for 1 epoch 3.587569236755371 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 1.4365\n",
      "Epoch 79 Loss 1.436452\n",
      "Time taken for 1 epoch 3.470017194747925 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 1.4361\n",
      "Epoch 80 Loss 1.436107\n",
      "Time taken for 1 epoch 3.4851176738739014 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 1.4301\n",
      "Epoch 81 Loss 1.430095\n",
      "Time taken for 1 epoch 3.494320869445801 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 1.4282\n",
      "Epoch 82 Loss 1.428160\n",
      "Time taken for 1 epoch 3.4739856719970703 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 1.4252\n",
      "Epoch 83 Loss 1.425189\n",
      "Time taken for 1 epoch 3.468071460723877 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 1.4222\n",
      "Epoch 84 Loss 1.422244\n",
      "Time taken for 1 epoch 3.5027518272399902 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 0 Loss 1.4192\n",
      "Epoch 85 Loss 1.419189\n",
      "Time taken for 1 epoch 3.5756654739379883 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 1.4162\n",
      "Epoch 86 Loss 1.416173\n",
      "Time taken for 1 epoch 3.506721019744873 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 1.4125\n",
      "Epoch 87 Loss 1.412550\n",
      "Time taken for 1 epoch 3.513664722442627 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 1.4092\n",
      "Epoch 88 Loss 1.409213\n",
      "Time taken for 1 epoch 3.5359861850738525 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 1.4059\n",
      "Epoch 89 Loss 1.405921\n",
      "Time taken for 1 epoch 3.5821120738983154 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 1.4025\n",
      "Epoch 90 Loss 1.402519\n",
      "Time taken for 1 epoch 3.5714352130889893 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 1.3992\n",
      "Epoch 91 Loss 1.399165\n",
      "Time taken for 1 epoch 3.6099140644073486 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 1.3959\n",
      "Epoch 92 Loss 1.395854\n",
      "Time taken for 1 epoch 3.57269024848938 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 1.3926\n",
      "Epoch 93 Loss 1.392551\n",
      "Time taken for 1 epoch 3.490795373916626 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 1.3893\n",
      "Epoch 94 Loss 1.389296\n",
      "Time taken for 1 epoch 3.7572009563446045 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 1.3860\n",
      "Epoch 95 Loss 1.386046\n",
      "Time taken for 1 epoch 3.671889305114746 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 1.3826\n",
      "Epoch 96 Loss 1.382604\n",
      "Time taken for 1 epoch 3.5454092025756836 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 1.3793\n",
      "Epoch 97 Loss 1.379287\n",
      "Time taken for 1 epoch 3.5057291984558105 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 1.3759\n",
      "Epoch 98 Loss 1.375903\n",
      "Time taken for 1 epoch 3.5602591037750244 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 1.3724\n",
      "Epoch 99 Loss 1.372413\n",
      "Time taken for 1 epoch 3.4892804622650146 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 1.3683\n",
      "Epoch 100 Loss 1.368343\n",
      "Time taken for 1 epoch 3.4670400619506836 sec\n",
      "\n",
      "Epoch 101 Batch 0 Loss 1.3657\n",
      "Epoch 101 Loss 1.365724\n",
      "Time taken for 1 epoch 3.5672335624694824 sec\n",
      "\n",
      "Epoch 102 Batch 0 Loss 1.3631\n",
      "Epoch 102 Loss 1.363124\n",
      "Time taken for 1 epoch 3.5672333240509033 sec\n",
      "\n",
      "Epoch 103 Batch 0 Loss 1.3604\n",
      "Epoch 103 Loss 1.360394\n",
      "Time taken for 1 epoch 3.5418055057525635 sec\n",
      "\n",
      "Epoch 104 Batch 0 Loss 1.3574\n",
      "Epoch 104 Loss 1.357424\n",
      "Time taken for 1 epoch 3.476959705352783 sec\n",
      "\n",
      "Epoch 105 Batch 0 Loss 1.3544\n",
      "Epoch 105 Loss 1.354379\n",
      "Time taken for 1 epoch 3.4858903884887695 sec\n",
      "\n",
      "Epoch 106 Batch 0 Loss 1.3507\n",
      "Epoch 106 Loss 1.350729\n",
      "Time taken for 1 epoch 3.500155210494995 sec\n",
      "\n",
      "Epoch 107 Batch 0 Loss 1.3469\n",
      "Epoch 107 Loss 1.346932\n",
      "Time taken for 1 epoch 3.5404491424560547 sec\n",
      "\n",
      "Epoch 108 Batch 0 Loss 1.3436\n",
      "Epoch 108 Loss 1.343623\n",
      "Time taken for 1 epoch 3.4754719734191895 sec\n",
      "\n",
      "Epoch 109 Batch 0 Loss 1.3402\n",
      "Epoch 109 Loss 1.340243\n",
      "Time taken for 1 epoch 3.4639968872070312 sec\n",
      "\n",
      "Epoch 110 Batch 0 Loss 1.3366\n",
      "Epoch 110 Loss 1.336588\n",
      "Time taken for 1 epoch 3.518129587173462 sec\n",
      "\n",
      "Epoch 111 Batch 0 Loss 1.3332\n",
      "Epoch 111 Loss 1.333240\n",
      "Time taken for 1 epoch 3.562767505645752 sec\n",
      "\n",
      "Epoch 112 Batch 0 Loss 1.3283\n",
      "Epoch 112 Loss 1.328341\n",
      "Time taken for 1 epoch 3.536998987197876 sec\n",
      "\n",
      "Epoch 113 Batch 0 Loss 1.3280\n",
      "Epoch 113 Loss 1.327989\n",
      "Time taken for 1 epoch 3.520112991333008 sec\n",
      "\n",
      "Epoch 114 Batch 0 Loss 1.3242\n",
      "Epoch 114 Loss 1.324220\n",
      "Time taken for 1 epoch 3.509489059448242 sec\n",
      "\n",
      "Epoch 115 Batch 0 Loss 1.3211\n",
      "Epoch 115 Loss 1.321073\n",
      "Time taken for 1 epoch 3.4933738708496094 sec\n",
      "\n",
      "Epoch 116 Batch 0 Loss 1.3167\n",
      "Epoch 116 Loss 1.316694\n",
      "Time taken for 1 epoch 3.501359701156616 sec\n",
      "\n",
      "Epoch 117 Batch 0 Loss 1.3130\n",
      "Epoch 117 Loss 1.313016\n",
      "Time taken for 1 epoch 3.4798147678375244 sec\n",
      "\n",
      "Epoch 118 Batch 0 Loss 1.3090\n",
      "Epoch 118 Loss 1.308999\n",
      "Time taken for 1 epoch 3.5524790287017822 sec\n",
      "\n",
      "Epoch 119 Batch 0 Loss 1.3058\n",
      "Epoch 119 Loss 1.305823\n",
      "Time taken for 1 epoch 3.582113027572632 sec\n",
      "\n",
      "Epoch 120 Batch 0 Loss 1.3018\n",
      "Epoch 120 Loss 1.301761\n",
      "Time taken for 1 epoch 3.6440844535827637 sec\n",
      "\n",
      "Epoch 121 Batch 0 Loss 1.2983\n",
      "Epoch 121 Loss 1.298329\n",
      "Time taken for 1 epoch 3.5211050510406494 sec\n",
      "\n",
      "Epoch 122 Batch 0 Loss 1.2941\n",
      "Epoch 122 Loss 1.294128\n",
      "Time taken for 1 epoch 3.5424327850341797 sec\n",
      "\n",
      "Epoch 123 Batch 0 Loss 1.2908\n",
      "Epoch 123 Loss 1.290802\n",
      "Time taken for 1 epoch 3.8211848735809326 sec\n",
      "\n",
      "Epoch 124 Batch 0 Loss 1.2871\n",
      "Epoch 124 Loss 1.287092\n",
      "Time taken for 1 epoch 3.6252646446228027 sec\n",
      "\n",
      "Epoch 125 Batch 0 Loss 1.2840\n",
      "Epoch 125 Loss 1.283995\n",
      "Time taken for 1 epoch 3.7720818519592285 sec\n",
      "\n",
      "Epoch 126 Batch 0 Loss 1.2809\n",
      "Epoch 126 Loss 1.280858\n",
      "Time taken for 1 epoch 4.282465696334839 sec\n",
      "\n",
      "Epoch 127 Batch 0 Loss 1.2775\n",
      "Epoch 127 Loss 1.277462\n",
      "Time taken for 1 epoch 4.426304340362549 sec\n",
      "\n",
      "Epoch 128 Batch 0 Loss 1.2740\n",
      "Epoch 128 Loss 1.274019\n",
      "Time taken for 1 epoch 4.534929275512695 sec\n",
      "\n",
      "Epoch 129 Batch 0 Loss 1.2706\n",
      "Epoch 129 Loss 1.270606\n",
      "Time taken for 1 epoch 3.8643364906311035 sec\n",
      "\n",
      "Epoch 130 Batch 0 Loss 1.2670\n",
      "Epoch 130 Loss 1.266961\n",
      "Time taken for 1 epoch 3.6966891288757324 sec\n",
      "\n",
      "Epoch 131 Batch 0 Loss 1.2634\n",
      "Epoch 131 Loss 1.263421\n",
      "Time taken for 1 epoch 3.525430679321289 sec\n",
      "\n",
      "Epoch 132 Batch 0 Loss 1.2619\n",
      "Epoch 132 Loss 1.261897\n",
      "Time taken for 1 epoch 3.5230884552001953 sec\n",
      "\n",
      "Epoch 133 Batch 0 Loss 1.2570\n",
      "Epoch 133 Loss 1.257022\n",
      "Time taken for 1 epoch 3.5424327850341797 sec\n",
      "\n",
      "Epoch 134 Batch 0 Loss 1.2543\n",
      "Epoch 134 Loss 1.254283\n",
      "Time taken for 1 epoch 3.529085397720337 sec\n",
      "\n",
      "Epoch 135 Batch 0 Loss 1.2516\n",
      "Epoch 135 Loss 1.251634\n",
      "Time taken for 1 epoch 3.538463830947876 sec\n",
      "\n",
      "Epoch 136 Batch 0 Loss 1.2485\n",
      "Epoch 136 Loss 1.248481\n",
      "Time taken for 1 epoch 3.573185443878174 sec\n",
      "\n",
      "Epoch 137 Batch 0 Loss 1.2454\n",
      "Epoch 137 Loss 1.245402\n",
      "Time taken for 1 epoch 3.5321528911590576 sec\n",
      "\n",
      "Epoch 138 Batch 0 Loss 1.2418\n",
      "Epoch 138 Loss 1.241834\n",
      "Time taken for 1 epoch 3.584097146987915 sec\n",
      "\n",
      "Epoch 139 Batch 0 Loss 1.2382\n",
      "Epoch 139 Loss 1.238213\n",
      "Time taken for 1 epoch 3.8499529361724854 sec\n",
      "\n",
      "Epoch 140 Batch 0 Loss 1.2350\n",
      "Epoch 140 Loss 1.234979\n",
      "Time taken for 1 epoch 3.581617593765259 sec\n",
      "\n",
      "Epoch 141 Batch 0 Loss 1.2315\n",
      "Epoch 141 Loss 1.231505\n",
      "Time taken for 1 epoch 3.6391520500183105 sec\n",
      "\n",
      "Epoch 142 Batch 0 Loss 1.2281\n",
      "Epoch 142 Loss 1.228120\n",
      "Time taken for 1 epoch 3.6477081775665283 sec\n",
      "\n",
      "Epoch 143 Batch 0 Loss 1.2259\n",
      "Epoch 143 Loss 1.225919\n",
      "Time taken for 1 epoch 3.8529293537139893 sec\n",
      "\n",
      "Epoch 144 Batch 0 Loss 1.2220\n",
      "Epoch 144 Loss 1.221967\n",
      "Time taken for 1 epoch 4.609825849533081 sec\n",
      "\n",
      "Epoch 145 Batch 0 Loss 1.2188\n",
      "Epoch 145 Loss 1.218779\n",
      "Time taken for 1 epoch 4.422832489013672 sec\n",
      "\n",
      "Epoch 146 Batch 0 Loss 1.2158\n",
      "Epoch 146 Loss 1.215784\n",
      "Time taken for 1 epoch 4.094977378845215 sec\n",
      "\n",
      "Epoch 147 Batch 0 Loss 1.2124\n",
      "Epoch 147 Loss 1.212449\n",
      "Time taken for 1 epoch 3.7507522106170654 sec\n",
      "\n",
      "Epoch 148 Batch 0 Loss 1.2092\n",
      "Epoch 148 Loss 1.209221\n",
      "Time taken for 1 epoch 3.818209648132324 sec\n",
      "\n",
      "Epoch 149 Batch 0 Loss 1.2062\n",
      "Epoch 149 Loss 1.206215\n",
      "Time taken for 1 epoch 3.983872652053833 sec\n",
      "\n",
      "Epoch 150 Batch 0 Loss 1.2028\n",
      "Epoch 150 Loss 1.202802\n",
      "Time taken for 1 epoch 3.546448230743408 sec\n",
      "\n",
      "Epoch 151 Batch 0 Loss 1.1996\n",
      "Epoch 151 Loss 1.199566\n",
      "Time taken for 1 epoch 3.654984474182129 sec\n",
      "\n",
      "Epoch 152 Batch 0 Loss 1.1966\n",
      "Epoch 152 Loss 1.196617\n",
      "Time taken for 1 epoch 3.55483341217041 sec\n",
      "\n",
      "Epoch 153 Batch 0 Loss 1.1933\n",
      "Epoch 153 Loss 1.193307\n",
      "Time taken for 1 epoch 3.52897310256958 sec\n",
      "\n",
      "Epoch 154 Batch 0 Loss 1.1902\n",
      "Epoch 154 Loss 1.190203\n",
      "Time taken for 1 epoch 3.521104335784912 sec\n",
      "\n",
      "Epoch 155 Batch 0 Loss 1.1872\n",
      "Epoch 155 Loss 1.187209\n",
      "Time taken for 1 epoch 3.519617795944214 sec\n",
      "\n",
      "Epoch 156 Batch 0 Loss 1.1840\n",
      "Epoch 156 Loss 1.183989\n",
      "Time taken for 1 epoch 3.514160394668579 sec\n",
      "\n",
      "Epoch 157 Batch 0 Loss 1.1807\n",
      "Epoch 157 Loss 1.180659\n",
      "Time taken for 1 epoch 3.839041233062744 sec\n",
      "\n",
      "Epoch 158 Batch 0 Loss 1.1776\n",
      "Epoch 158 Loss 1.177646\n",
      "Time taken for 1 epoch 3.607409954071045 sec\n",
      "\n",
      "Epoch 159 Batch 0 Loss 1.1746\n",
      "Epoch 159 Loss 1.174578\n",
      "Time taken for 1 epoch 3.7522406578063965 sec\n",
      "\n",
      "Epoch 160 Batch 0 Loss 1.1714\n",
      "Epoch 160 Loss 1.171369\n",
      "Time taken for 1 epoch 3.6580007076263428 sec\n",
      "\n",
      "Epoch 161 Batch 0 Loss 1.1685\n",
      "Epoch 161 Loss 1.168546\n",
      "Time taken for 1 epoch 3.6024491786956787 sec\n",
      "\n",
      "Epoch 162 Batch 0 Loss 1.1655\n",
      "Epoch 162 Loss 1.165549\n",
      "Time taken for 1 epoch 3.8072972297668457 sec\n",
      "\n",
      "Epoch 163 Batch 0 Loss 1.1621\n",
      "Epoch 163 Loss 1.162134\n",
      "Time taken for 1 epoch 4.565680980682373 sec\n",
      "\n",
      "Epoch 164 Batch 0 Loss 1.1600\n",
      "Epoch 164 Loss 1.159951\n",
      "Time taken for 1 epoch 4.339008808135986 sec\n",
      "\n",
      "Epoch 165 Batch 0 Loss 1.1568\n",
      "Epoch 165 Loss 1.156752\n",
      "Time taken for 1 epoch 3.754721164703369 sec\n",
      "\n",
      "Epoch 166 Batch 0 Loss 1.1542\n",
      "Epoch 166 Loss 1.154248\n",
      "Time taken for 1 epoch 3.7547216415405273 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167 Batch 0 Loss 1.1509\n",
      "Epoch 167 Loss 1.150938\n",
      "Time taken for 1 epoch 3.610384464263916 sec\n",
      "\n",
      "Epoch 168 Batch 0 Loss 1.1480\n",
      "Epoch 168 Loss 1.148008\n",
      "Time taken for 1 epoch 3.720496892929077 sec\n",
      "\n",
      "Epoch 169 Batch 0 Loss 1.1454\n",
      "Epoch 169 Loss 1.145411\n",
      "Time taken for 1 epoch 3.5388600826263428 sec\n",
      "\n",
      "Epoch 170 Batch 0 Loss 1.1422\n",
      "Epoch 170 Loss 1.142240\n",
      "Time taken for 1 epoch 3.603755235671997 sec\n",
      "\n",
      "Epoch 171 Batch 0 Loss 1.1393\n",
      "Epoch 171 Loss 1.139310\n",
      "Time taken for 1 epoch 3.8430092334747314 sec\n",
      "\n",
      "Epoch 172 Batch 0 Loss 1.1364\n",
      "Epoch 172 Loss 1.136375\n",
      "Time taken for 1 epoch 3.799360990524292 sec\n",
      "\n",
      "Epoch 173 Batch 0 Loss 1.1357\n",
      "Epoch 173 Loss 1.135685\n",
      "Time taken for 1 epoch 4.051825761795044 sec\n",
      "\n",
      "Epoch 174 Batch 0 Loss 1.1327\n",
      "Epoch 174 Loss 1.132744\n",
      "Time taken for 1 epoch 4.3018083572387695 sec\n",
      "\n",
      "Epoch 175 Batch 0 Loss 1.1292\n",
      "Epoch 175 Loss 1.129157\n",
      "Time taken for 1 epoch 4.447137117385864 sec\n",
      "\n",
      "Epoch 176 Batch 0 Loss 1.1318\n",
      "Epoch 176 Loss 1.131752\n",
      "Time taken for 1 epoch 3.933281421661377 sec\n",
      "\n",
      "Epoch 177 Batch 0 Loss 1.1408\n",
      "Epoch 177 Loss 1.140752\n",
      "Time taken for 1 epoch 3.7319047451019287 sec\n",
      "\n",
      "Epoch 178 Batch 0 Loss 1.1360\n",
      "Epoch 178 Loss 1.136019\n",
      "Time taken for 1 epoch 3.55273699760437 sec\n",
      "\n",
      "Epoch 179 Batch 0 Loss 1.1286\n",
      "Epoch 179 Loss 1.128569\n",
      "Time taken for 1 epoch 3.5860886573791504 sec\n",
      "\n",
      "Epoch 180 Batch 0 Loss 1.1288\n",
      "Epoch 180 Loss 1.128768\n",
      "Time taken for 1 epoch 3.674283742904663 sec\n",
      "\n",
      "Epoch 181 Batch 0 Loss 1.1239\n",
      "Epoch 181 Loss 1.123916\n",
      "Time taken for 1 epoch 3.601970672607422 sec\n",
      "\n",
      "Epoch 182 Batch 0 Loss 1.1183\n",
      "Epoch 182 Loss 1.118273\n",
      "Time taken for 1 epoch 3.674865245819092 sec\n",
      "\n",
      "Epoch 183 Batch 0 Loss 1.1245\n",
      "Epoch 183 Loss 1.124482\n",
      "Time taken for 1 epoch 3.6862740516662598 sec\n",
      "\n",
      "Epoch 184 Batch 0 Loss 1.1178\n",
      "Epoch 184 Loss 1.117774\n",
      "Time taken for 1 epoch 3.61236310005188 sec\n",
      "\n",
      "Epoch 185 Batch 0 Loss 1.1215\n",
      "Epoch 185 Loss 1.121545\n",
      "Time taken for 1 epoch 3.614922285079956 sec\n",
      "\n",
      "Epoch 186 Batch 0 Loss 1.1199\n",
      "Epoch 186 Loss 1.119874\n",
      "Time taken for 1 epoch 3.6108810901641846 sec\n",
      "\n",
      "Epoch 187 Batch 0 Loss 1.1135\n",
      "Epoch 187 Loss 1.113549\n",
      "Time taken for 1 epoch 3.643968343734741 sec\n",
      "\n",
      "Epoch 188 Batch 0 Loss 1.1218\n",
      "Epoch 188 Loss 1.121761\n",
      "Time taken for 1 epoch 3.6188387870788574 sec\n",
      "\n",
      "Epoch 189 Batch 0 Loss 1.1186\n",
      "Epoch 189 Loss 1.118589\n",
      "Time taken for 1 epoch 3.6283810138702393 sec\n",
      "\n",
      "Epoch 190 Batch 0 Loss 1.1156\n",
      "Epoch 190 Loss 1.115630\n",
      "Time taken for 1 epoch 3.6272497177124023 sec\n",
      "\n",
      "Epoch 191 Batch 0 Loss 1.1210\n",
      "Epoch 191 Loss 1.121044\n",
      "Time taken for 1 epoch 3.6364285945892334 sec\n",
      "\n",
      "Epoch 192 Batch 0 Loss 1.1183\n",
      "Epoch 192 Loss 1.118306\n",
      "Time taken for 1 epoch 3.605621099472046 sec\n",
      "\n",
      "Epoch 193 Batch 0 Loss 1.1156\n",
      "Epoch 193 Loss 1.115614\n",
      "Time taken for 1 epoch 3.5797955989837646 sec\n",
      "\n",
      "Epoch 194 Batch 0 Loss 1.1100\n",
      "Epoch 194 Loss 1.110048\n",
      "Time taken for 1 epoch 3.6062633991241455 sec\n",
      "\n",
      "Epoch 195 Batch 0 Loss 1.1070\n",
      "Epoch 195 Loss 1.107037\n",
      "Time taken for 1 epoch 3.5407843589782715 sec\n",
      "\n",
      "Epoch 196 Batch 0 Loss 1.1033\n",
      "Epoch 196 Loss 1.103342\n",
      "Time taken for 1 epoch 3.573681592941284 sec\n",
      "\n",
      "Epoch 197 Batch 0 Loss 1.0996\n",
      "Epoch 197 Loss 1.099581\n",
      "Time taken for 1 epoch 3.60691237449646 sec\n",
      "\n",
      "Epoch 198 Batch 0 Loss 1.0972\n",
      "Epoch 198 Loss 1.097192\n",
      "Time taken for 1 epoch 3.656017303466797 sec\n",
      "\n",
      "Epoch 199 Batch 0 Loss 1.0927\n",
      "Epoch 199 Loss 1.092732\n",
      "Time taken for 1 epoch 3.6589925289154053 sec\n",
      "\n",
      "Epoch 200 Batch 0 Loss 1.0905\n",
      "Epoch 200 Loss 1.090509\n",
      "Time taken for 1 epoch 3.662961721420288 sec\n",
      "\n",
      "Epoch 201 Batch 0 Loss 1.0858\n",
      "Epoch 201 Loss 1.085820\n",
      "Time taken for 1 epoch 3.698646068572998 sec\n",
      "\n",
      "Epoch 202 Batch 0 Loss 1.0818\n",
      "Epoch 202 Loss 1.081752\n",
      "Time taken for 1 epoch 3.6578564643859863 sec\n",
      "\n",
      "Epoch 203 Batch 0 Loss 1.0790\n",
      "Epoch 203 Loss 1.078963\n",
      "Time taken for 1 epoch 3.6316158771514893 sec\n",
      "\n",
      "Epoch 204 Batch 0 Loss 1.0750\n",
      "Epoch 204 Loss 1.074951\n",
      "Time taken for 1 epoch 3.6248629093170166 sec\n",
      "\n",
      "Epoch 205 Batch 0 Loss 1.0709\n",
      "Epoch 205 Loss 1.070861\n",
      "Time taken for 1 epoch 3.5716965198516846 sec\n",
      "\n",
      "Epoch 206 Batch 0 Loss 1.0670\n",
      "Epoch 206 Loss 1.066955\n",
      "Time taken for 1 epoch 3.5991058349609375 sec\n",
      "\n",
      "Epoch 207 Batch 0 Loss 1.0639\n",
      "Epoch 207 Loss 1.063911\n",
      "Time taken for 1 epoch 3.7482728958129883 sec\n",
      "\n",
      "Epoch 208 Batch 0 Loss 1.0618\n",
      "Epoch 208 Loss 1.061775\n",
      "Time taken for 1 epoch 3.6242213249206543 sec\n",
      "\n",
      "Epoch 209 Batch 0 Loss 1.0590\n",
      "Epoch 209 Loss 1.059002\n",
      "Time taken for 1 epoch 3.627744436264038 sec\n",
      "\n",
      "Epoch 210 Batch 0 Loss 1.0608\n",
      "Epoch 210 Loss 1.060782\n",
      "Time taken for 1 epoch 3.68084716796875 sec\n",
      "\n",
      "Epoch 211 Batch 0 Loss 1.0562\n",
      "Epoch 211 Loss 1.056228\n",
      "Time taken for 1 epoch 3.680816173553467 sec\n",
      "\n",
      "Epoch 212 Batch 0 Loss 1.0513\n",
      "Epoch 212 Loss 1.051267\n",
      "Time taken for 1 epoch 3.6674246788024902 sec\n",
      "\n",
      "Epoch 213 Batch 0 Loss 1.0484\n",
      "Epoch 213 Loss 1.048400\n",
      "Time taken for 1 epoch 3.6891233921051025 sec\n",
      "\n",
      "Epoch 214 Batch 0 Loss 1.0458\n",
      "Epoch 214 Loss 1.045769\n",
      "Time taken for 1 epoch 3.6718883514404297 sec\n",
      "\n",
      "Epoch 215 Batch 0 Loss 1.0443\n",
      "Epoch 215 Loss 1.044251\n",
      "Time taken for 1 epoch 3.585584878921509 sec\n",
      "\n",
      "Epoch 216 Batch 0 Loss 1.0412\n",
      "Epoch 216 Loss 1.041178\n",
      "Time taken for 1 epoch 3.621793270111084 sec\n",
      "\n",
      "Epoch 217 Batch 0 Loss 1.0389\n",
      "Epoch 217 Loss 1.038860\n",
      "Time taken for 1 epoch 3.5223517417907715 sec\n",
      "\n",
      "Epoch 218 Batch 0 Loss 1.0356\n",
      "Epoch 218 Loss 1.035631\n",
      "Time taken for 1 epoch 3.5508649349212646 sec\n",
      "\n",
      "Epoch 219 Batch 0 Loss 1.0334\n",
      "Epoch 219 Loss 1.033400\n",
      "Time taken for 1 epoch 3.527552843093872 sec\n",
      "\n",
      "Epoch 220 Batch 0 Loss 1.0303\n",
      "Epoch 220 Loss 1.030268\n",
      "Time taken for 1 epoch 3.487675905227661 sec\n",
      "\n",
      "Epoch 221 Batch 0 Loss 1.0278\n",
      "Epoch 221 Loss 1.027776\n",
      "Time taken for 1 epoch 3.5181522369384766 sec\n",
      "\n",
      "Epoch 222 Batch 0 Loss 1.0252\n",
      "Epoch 222 Loss 1.025229\n",
      "Time taken for 1 epoch 3.515892505645752 sec\n",
      "\n",
      "Epoch 223 Batch 0 Loss 1.0236\n",
      "Epoch 223 Loss 1.023619\n",
      "Time taken for 1 epoch 3.5306379795074463 sec\n",
      "\n",
      "Epoch 224 Batch 0 Loss 1.0209\n",
      "Epoch 224 Loss 1.020948\n",
      "Time taken for 1 epoch 3.5632641315460205 sec\n",
      "\n",
      "Epoch 225 Batch 0 Loss 1.0194\n",
      "Epoch 225 Loss 1.019391\n",
      "Time taken for 1 epoch 3.4898569583892822 sec\n",
      "\n",
      "Epoch 226 Batch 0 Loss 1.0169\n",
      "Epoch 226 Loss 1.016888\n",
      "Time taken for 1 epoch 3.544912576675415 sec\n",
      "\n",
      "Epoch 227 Batch 0 Loss 1.0136\n",
      "Epoch 227 Loss 1.013624\n",
      "Time taken for 1 epoch 3.565136671066284 sec\n",
      "\n",
      "Epoch 228 Batch 0 Loss 1.0112\n",
      "Epoch 228 Loss 1.011210\n",
      "Time taken for 1 epoch 3.5335044860839844 sec\n",
      "\n",
      "Epoch 229 Batch 0 Loss 1.0082\n",
      "Epoch 229 Loss 1.008224\n",
      "Time taken for 1 epoch 3.5171382427215576 sec\n",
      "\n",
      "Epoch 230 Batch 0 Loss 1.0062\n",
      "Epoch 230 Loss 1.006218\n",
      "Time taken for 1 epoch 3.5123798847198486 sec\n",
      "\n",
      "Epoch 231 Batch 0 Loss 1.0040\n",
      "Epoch 231 Loss 1.004032\n",
      "Time taken for 1 epoch 3.607966661453247 sec\n",
      "\n",
      "Epoch 232 Batch 0 Loss 1.0015\n",
      "Epoch 232 Loss 1.001512\n",
      "Time taken for 1 epoch 3.683793306350708 sec\n",
      "\n",
      "Epoch 233 Batch 0 Loss 0.9995\n",
      "Epoch 233 Loss 0.999550\n",
      "Time taken for 1 epoch 3.6887524127960205 sec\n",
      "\n",
      "Epoch 234 Batch 0 Loss 0.9966\n",
      "Epoch 234 Loss 0.996645\n",
      "Time taken for 1 epoch 3.4898252487182617 sec\n",
      "\n",
      "Epoch 235 Batch 0 Loss 0.9943\n",
      "Epoch 235 Loss 0.994269\n",
      "Time taken for 1 epoch 3.549872636795044 sec\n",
      "\n",
      "Epoch 236 Batch 0 Loss 0.9922\n",
      "Epoch 236 Loss 0.992208\n",
      "Time taken for 1 epoch 3.545905351638794 sec\n",
      "\n",
      "Epoch 237 Batch 0 Loss 0.9897\n",
      "Epoch 237 Loss 0.989743\n",
      "Time taken for 1 epoch 3.568225383758545 sec\n",
      "\n",
      "Epoch 238 Batch 0 Loss 0.9871\n",
      "Epoch 238 Loss 0.987126\n",
      "Time taken for 1 epoch 3.5388853549957275 sec\n",
      "\n",
      "Epoch 239 Batch 0 Loss 0.9854\n",
      "Epoch 239 Loss 0.985370\n",
      "Time taken for 1 epoch 3.495126962661743 sec\n",
      "\n",
      "Epoch 240 Batch 0 Loss 0.9829\n",
      "Epoch 240 Loss 0.982859\n",
      "Time taken for 1 epoch 3.54392147064209 sec\n",
      "\n",
      "Epoch 241 Batch 0 Loss 0.9808\n",
      "Epoch 241 Loss 0.980809\n",
      "Time taken for 1 epoch 3.610879898071289 sec\n",
      "\n",
      "Epoch 242 Batch 0 Loss 0.9782\n",
      "Epoch 242 Loss 0.978187\n",
      "Time taken for 1 epoch 3.5885608196258545 sec\n",
      "\n",
      "Epoch 243 Batch 0 Loss 0.9757\n",
      "Epoch 243 Loss 0.975667\n",
      "Time taken for 1 epoch 3.523090362548828 sec\n",
      "\n",
      "Epoch 244 Batch 0 Loss 0.9735\n",
      "Epoch 244 Loss 0.973530\n",
      "Time taken for 1 epoch 3.5184621810913086 sec\n",
      "\n",
      "Epoch 245 Batch 0 Loss 0.9710\n",
      "Epoch 245 Loss 0.970959\n",
      "Time taken for 1 epoch 3.558281421661377 sec\n",
      "\n",
      "Epoch 246 Batch 0 Loss 0.9692\n",
      "Epoch 246 Loss 0.969174\n",
      "Time taken for 1 epoch 3.5861246585845947 sec\n",
      "\n",
      "Epoch 247 Batch 0 Loss 0.9662\n",
      "Epoch 247 Loss 0.966225\n",
      "Time taken for 1 epoch 3.510540723800659 sec\n",
      "\n",
      "Epoch 248 Batch 0 Loss 0.9642\n",
      "Epoch 248 Loss 0.964217\n",
      "Time taken for 1 epoch 3.51965594291687 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249 Batch 0 Loss 0.9620\n",
      "Epoch 249 Loss 0.961982\n",
      "Time taken for 1 epoch 3.535984754562378 sec\n",
      "\n",
      "Epoch 250 Batch 0 Loss 0.9600\n",
      "Epoch 250 Loss 0.960032\n",
      "Time taken for 1 epoch 3.5890562534332275 sec\n",
      "\n",
      "Epoch 251 Batch 0 Loss 0.9582\n",
      "Epoch 251 Loss 0.958186\n",
      "Time taken for 1 epoch 3.4774951934814453 sec\n",
      "\n",
      "Epoch 252 Batch 0 Loss 0.9556\n",
      "Epoch 252 Loss 0.955601\n",
      "Time taken for 1 epoch 3.5468976497650146 sec\n",
      "\n",
      "Epoch 253 Batch 0 Loss 0.9532\n",
      "Epoch 253 Loss 0.953208\n",
      "Time taken for 1 epoch 3.576159715652466 sec\n",
      "\n",
      "Epoch 254 Batch 0 Loss 0.9511\n",
      "Epoch 254 Loss 0.951104\n",
      "Time taken for 1 epoch 3.6704840660095215 sec\n",
      "\n",
      "Epoch 255 Batch 0 Loss 0.9487\n",
      "Epoch 255 Loss 0.948747\n",
      "Time taken for 1 epoch 3.5877742767333984 sec\n",
      "\n",
      "Epoch 256 Batch 0 Loss 0.9468\n",
      "Epoch 256 Loss 0.946834\n",
      "Time taken for 1 epoch 3.59110164642334 sec\n",
      "\n",
      "Epoch 257 Batch 0 Loss 0.9440\n",
      "Epoch 257 Loss 0.943961\n",
      "Time taken for 1 epoch 3.5885610580444336 sec\n",
      "\n",
      "Epoch 258 Batch 0 Loss 0.9416\n",
      "Epoch 258 Loss 0.941615\n",
      "Time taken for 1 epoch 3.6108810901641846 sec\n",
      "\n",
      "Epoch 259 Batch 0 Loss 0.9390\n",
      "Epoch 259 Loss 0.939044\n",
      "Time taken for 1 epoch 3.636674404144287 sec\n",
      "\n",
      "Epoch 260 Batch 0 Loss 0.9370\n",
      "Epoch 260 Loss 0.936963\n",
      "Time taken for 1 epoch 3.5389599800109863 sec\n",
      "\n",
      "Epoch 261 Batch 0 Loss 0.9349\n",
      "Epoch 261 Loss 0.934946\n",
      "Time taken for 1 epoch 3.3822245597839355 sec\n",
      "\n",
      "Epoch 262 Batch 0 Loss 0.9325\n",
      "Epoch 262 Loss 0.932459\n",
      "Time taken for 1 epoch 3.407576084136963 sec\n",
      "\n",
      "Epoch 263 Batch 0 Loss 0.9302\n",
      "Epoch 263 Loss 0.930161\n",
      "Time taken for 1 epoch 3.3117926120758057 sec\n",
      "\n",
      "Epoch 264 Batch 0 Loss 0.9285\n",
      "Epoch 264 Loss 0.928546\n",
      "Time taken for 1 epoch 3.3955187797546387 sec\n",
      "\n",
      "Epoch 265 Batch 0 Loss 0.9263\n",
      "Epoch 265 Loss 0.926281\n",
      "Time taken for 1 epoch 3.282003402709961 sec\n",
      "\n",
      "Epoch 266 Batch 0 Loss 0.9244\n",
      "Epoch 266 Loss 0.924380\n",
      "Time taken for 1 epoch 3.3064935207366943 sec\n",
      "\n",
      "Epoch 267 Batch 0 Loss 0.9217\n",
      "Epoch 267 Loss 0.921711\n",
      "Time taken for 1 epoch 3.332810401916504 sec\n",
      "\n",
      "Epoch 268 Batch 0 Loss 0.9194\n",
      "Epoch 268 Loss 0.919412\n",
      "Time taken for 1 epoch 3.3140909671783447 sec\n",
      "\n",
      "Epoch 269 Batch 0 Loss 0.9173\n",
      "Epoch 269 Loss 0.917274\n",
      "Time taken for 1 epoch 3.2562410831451416 sec\n",
      "\n",
      "Epoch 270 Batch 0 Loss 0.9151\n",
      "Epoch 270 Loss 0.915123\n",
      "Time taken for 1 epoch 4.163921594619751 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        \n",
    "        steps = 0\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            img_tensor, target, _ = batch[0], batch[1], batch[2]\n",
    "            \n",
    "            batch_loss, t_loss = train_step(img_tensor, target)\n",
    "            total_loss += t_loss.item()\n",
    "            \n",
    "            if idx % 500 == 0:\n",
    "                print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                  epoch + 1, idx, batch_loss.item() / int(target.shape[1])))\n",
    "            steps += 1\n",
    "            \n",
    "        if epoch == 0:\n",
    "            dataloader.dataset.set_use_cache(True)\n",
    "            dataloader.num_workers = 3\n",
    "\n",
    "        # storing the epoch end loss value to plot later\n",
    "        loss_plot.append(total_loss / steps)\n",
    "        \n",
    "        if epoch % 100 == 0 and epoch > 0:\n",
    "            torch.save(model.state_dict(), 'model')\n",
    "\n",
    "        print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                             total_loss/steps))\n",
    "        print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, cap, name = dataset[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   4,   21,  888,   54,    9,  495,  183,   26, 1913, 3090,    2,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0], dtype=torch.int16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extracted_data/train/vecs/COCO_train2014_000000299675'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im.unsqueeze(0)\n",
    "cap = cap.unsqueeze(0)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 2048])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a white square kitchen with tile floor that needs repairs <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab.decode_sentence(cap.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man',\n",
       " 'and',\n",
       " 'a',\n",
       " 'man']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "out = model.evaluate(im)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_image_web('https://scontent.fbeg1-1.fna.fbcdn.net/v/t1.15752-9/106495264_270801397340750_5352596102031662927_n.jpg?_nc_cat=111&_nc_sid=b96e70&_nc_eui2=AeHUk7NrGbTNGQAAWPZuOseGdyXefbU8isZ3Jd59tTyKxlrvw8eGUmMqySImBZ4oCy2B2dfMEUR0-VKmJ7nQm1EF&_nc_ohc=f6VChx9r9cEAX_nfj3j&_nc_ht=scontent.fbeg1-1.fna&oh=7f53e6371c6af62fed5640d62a8df943&oe=5F225805')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_image_web('https://cdn.vox-cdn.com/thumbor/vQ_TbE_e04tsWLhQqMCG40Nn33o=/0x0:600x450/1200x900/filters:focal(0x0:600x450):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19650209/Kitchen_0719-Brookline_Shot7A-Kitchen_StraightOnFromDiningArea-27.0.0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = preprocess_image('mscoco/train/img/COCO_train2014_000000028149')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(1,64,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'very',\n",
       " 'clean',\n",
       " 'and',\n",
       " 'well',\n",
       " 'decorated',\n",
       " 'empty',\n",
       " 'bathroom',\n",
       " '<end>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.evaluate(img)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
