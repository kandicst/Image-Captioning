{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data_train_dir = 'extracted_data/train/'\n",
    "extracted_data_test_dir = 'extracted_data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file, 'r') as f1:\n",
    "        return json.loads(f1.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mscoco/train/img/COCO_train2014_000000318556 <START> A very clean and well decorated empty bathroom <END>\n"
     ]
    }
   ],
   "source": [
    "train_captions = load_json(extracted_data_train_dir + 'captions.json')\n",
    "train_image_paths = load_json(extracted_data_train_dir + 'image_paths.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_image_paths[0], train_captions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "word_to_idx = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, '<unk>': 3}\n",
    "idx_to_word = {0: \"<pad>\", 1: \"<start>\", 2: \"<end>\", 3: '<unk>'}\n",
    "\n",
    "unk_idx = word_to_idx['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_caption(caption):\n",
    "    return caption.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249454"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for caption in train_captions:\n",
    "    caption = preprocess_caption(caption)\n",
    "    for word in caption:\n",
    "        if word in word_freq: word_freq[word] += 1\n",
    "        else: word_freq[word] = 1\n",
    "\n",
    "word_freq.pop(\"<start>\", None)\n",
    "word_freq.pop(\"<end>\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = len(word_to_idx)\n",
    "print(start_idx)\n",
    "\n",
    "# get top K words\n",
    "for word in sorted(word_freq, key=word_freq.get, reverse=True):\n",
    "    word_to_idx[word] = start_idx\n",
    "    idx_to_word[start_idx] = word\n",
    "    start_idx += 1\n",
    "    if start_idx >= max_vocab_size: break\n",
    "\n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence):\n",
    "    return [word_to_idx.get(x, unk_idx) for x in preprocess_caption(sentence)]\n",
    "\n",
    "def decode_sentence(indices):\n",
    "    return \" \".join([idx_to_word.get(x, '<unk>') for x in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132, 11, 665, 1931]\n",
      "this is not fun\n"
     ]
    }
   ],
   "source": [
    "sentence = 'This is not fun'\n",
    "encoded = encode_sentence(sentence)\n",
    "decoded = decode_sentence(encoded)\n",
    "\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = Vocabulary(train_captions, max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 125, 473, 10, 742, 480, 230, 38, 2]\n",
      "<start> a very clean and well decorated empty bathroom <end>\n",
      "<START> A very clean and well decorated empty bathroom <END>\n"
     ]
    }
   ],
   "source": [
    "print(train_vocab.encoded_captions[0])\n",
    "print(train_vocab.decode_sentence(train_vocab.encoded_captions[0]))\n",
    "print(train_captions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoded captions for each caption in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 125, 473, 10, 742, 480, 230, 38, 2]]\n",
      "<start> a very clean and well decorated empty bathroom <end>\n",
      "['<START> A very clean and well decorated empty bathroom <END>']\n"
     ]
    }
   ],
   "source": [
    "encoded_captions_train = [encode_sentence(x) for x in train_captions]\n",
    "\n",
    "print(encoded_captions_train[:1])\n",
    "print(decode_sentence(encoded_captions_train[0]))\n",
    "print(train_captions[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249454"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_captions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from MyDataset import MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249454\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "wat = [torch.tensor(x[1:], dtype=torch.int16) for x in train_vocab.encoded_captions]\n",
    "padded = pad_sequence(wat).permute(1, 0)\n",
    "print(len(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4, 125, 473,  10, 742, 480, 230,  38,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0], dtype=torch.int16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(enc_captions=padded,\n",
    "                    image_paths=train_image_paths,\n",
    "                   data_dir=extracted_data_train_dir + 'vecs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small dataste\n",
    "dataset = MyDataset(enc_captions=padded[:300],\n",
    "                    image_paths=train_image_paths[:300],\n",
    "                   data_dir=extracted_data_train_dir + 'vecs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2048])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=256, \n",
    "                         num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 64, 2048])\n",
      "torch.Size([50])\n",
      "[4, 125, 473, 10, 742, 480, 230, 38, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "a very clean and well decorated empty bathroom <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(dataloader):\n",
    "    imgs, labels = data[0], data[1]\n",
    "    print(idx, imgs.shape)\n",
    "    print(labels[0].shape)\n",
    "    print(labels[0].tolist())\n",
    "    print(decode_sentence(labels[0].tolist()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.Encoder import Encoder\n",
    "from layers.Decoder import Decoder\n",
    "from layers.Attention import Attention\n",
    "from layers.End2End import End2End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = len(SRC.vocab)\n",
    "# OUTPUT_DIM = len(TRG.vocab)\n",
    "DEC_EMB_DIM = 1024\n",
    "ENC_INPUT = 2048\n",
    "ENC_OUTPUT = 256\n",
    "DEC_HID_DIM = 512\n",
    "DEC_OUTPUT = 512\n",
    "ATTN_DIM = 512\n",
    "EMB_DIM = 256\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,447,889 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = End2End(ENC_INPUT, ENC_OUTPUT, DEC_HID_DIM, DEC_OUTPUT,\n",
    "               EMB_DIM, ATTN_DIM, train_vocab, criterion, device)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []\n",
    "\n",
    "def train_step(batch, captions):\n",
    "    \n",
    "    batch_size = captions.shape[0]\n",
    "    caption_length = captions.shape[1]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    _, loss = model(batch, captions)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss = (loss / int(caption_length))\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.6578\n",
      "Epoch 1 Loss 0.518644\n",
      "Time taken for 1 epoch 3.7885286808013916 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6541\n",
      "Epoch 2 Loss 0.515746\n",
      "Time taken for 1 epoch 3.7794599533081055 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6504\n",
      "Epoch 3 Loss 0.512877\n",
      "Time taken for 1 epoch 3.6797139644622803 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.6468\n",
      "Epoch 4 Loss 0.509986\n",
      "Time taken for 1 epoch 3.7026729583740234 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.6432\n",
      "Epoch 5 Loss 0.507105\n",
      "Time taken for 1 epoch 4.105150461196899 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.6397\n",
      "Epoch 6 Loss 0.504250\n",
      "Time taken for 1 epoch 3.887897253036499 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6361\n",
      "Epoch 7 Loss 0.501390\n",
      "Time taken for 1 epoch 3.930474042892456 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.6326\n",
      "Epoch 8 Loss 0.498522\n",
      "Time taken for 1 epoch 3.9240503311157227 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.6292\n",
      "Epoch 9 Loss 0.495667\n",
      "Time taken for 1 epoch 3.8865299224853516 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.6257\n",
      "Epoch 10 Loss 0.492814\n",
      "Time taken for 1 epoch 4.003027677536011 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6223\n",
      "Epoch 11 Loss 0.489962\n",
      "Time taken for 1 epoch 3.8550424575805664 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.6189\n",
      "Epoch 12 Loss 0.487114\n",
      "Time taken for 1 epoch 3.712491750717163 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.6155\n",
      "Epoch 13 Loss 0.484274\n",
      "Time taken for 1 epoch 3.640342950820923 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.6122\n",
      "Epoch 14 Loss 0.481434\n",
      "Time taken for 1 epoch 3.603444814682007 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.6088\n",
      "Epoch 15 Loss 0.478598\n",
      "Time taken for 1 epoch 3.740838050842285 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.6056\n",
      "Epoch 16 Loss 0.475796\n",
      "Time taken for 1 epoch 3.7329554557800293 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.6023\n",
      "Epoch 17 Loss 0.472989\n",
      "Time taken for 1 epoch 3.6351847648620605 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.5990\n",
      "Epoch 18 Loss 0.470180\n",
      "Time taken for 1 epoch 3.779909133911133 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.5958\n",
      "Epoch 19 Loss 0.467392\n",
      "Time taken for 1 epoch 3.9098854064941406 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.5926\n",
      "Epoch 20 Loss 0.464623\n",
      "Time taken for 1 epoch 3.7196731567382812 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.5894\n",
      "Epoch 21 Loss 0.461860\n",
      "Time taken for 1 epoch 3.6032350063323975 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.5862\n",
      "Epoch 22 Loss 0.459109\n",
      "Time taken for 1 epoch 3.5784220695495605 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.5831\n",
      "Epoch 23 Loss 0.456361\n",
      "Time taken for 1 epoch 3.6453745365142822 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.5800\n",
      "Epoch 24 Loss 0.453651\n",
      "Time taken for 1 epoch 3.685657501220703 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.5769\n",
      "Epoch 25 Loss 0.450929\n",
      "Time taken for 1 epoch 3.6206459999084473 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.5738\n",
      "Epoch 26 Loss 0.448234\n",
      "Time taken for 1 epoch 3.656287908554077 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.5707\n",
      "Epoch 27 Loss 0.445552\n",
      "Time taken for 1 epoch 3.635725975036621 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.5677\n",
      "Epoch 28 Loss 0.442879\n",
      "Time taken for 1 epoch 3.5845870971679688 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.5647\n",
      "Epoch 29 Loss 0.440234\n",
      "Time taken for 1 epoch 3.5833308696746826 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.5617\n",
      "Epoch 30 Loss 0.437569\n",
      "Time taken for 1 epoch 3.554945468902588 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.5588\n",
      "Epoch 31 Loss 0.434954\n",
      "Time taken for 1 epoch 3.5630223751068115 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.5558\n",
      "Epoch 32 Loss 0.432337\n",
      "Time taken for 1 epoch 3.619326591491699 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.5528\n",
      "Epoch 33 Loss 0.429714\n",
      "Time taken for 1 epoch 3.7056353092193604 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        \n",
    "        steps = 0\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            img_tensor, target, _ = batch[0], batch[1], batch[2]\n",
    "            \n",
    "            batch_loss, t_loss = train_step(img_tensor, target)\n",
    "            total_loss += t_loss.item()\n",
    "#             return\n",
    "            \n",
    "            if idx % 500 == 0:\n",
    "                print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                  epoch + 1, idx, batch_loss.item() / int(target.shape[1])))\n",
    "            steps += 1\n",
    "            \n",
    "        if epoch == 0:\n",
    "            dataloader.dataset.set_use_cache(True)\n",
    "            dataloader.num_workers = 4\n",
    "\n",
    "        # storing the epoch end loss value to plot later\n",
    "        loss_plot.append(total_loss / steps)\n",
    "\n",
    "        print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                             total_loss/steps))\n",
    "        print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, cap, name = dataset[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4,  38,   9,   4, 510,  31,   5, 195,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0], dtype=torch.int16)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extracted_data/train/vecs/COCO_train2014_000000028149'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im.unsqueeze(0)\n",
    "cap = cap.unsqueeze(0)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a bathroom with a tv near the mirror <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(cap.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.8399, -10.5591,   2.0626,  ...,  -9.0118,  -9.3886,  -9.5738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.8901, -10.9618,   7.5945,  ..., -10.8653, -10.6317, -11.8988]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.evaluate(im)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.8399, -10.5591,   2.0626,  ...,  -9.0118,  -9.3886,  -9.5738]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -9.3490, -10.4534,   6.3471,  ..., -10.1493, -11.0170, -11.6716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-6.7172, -9.8830,  4.2961,  ..., -7.7714, -7.9196, -8.4553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.0643, -9.0360,  0.8131,  ..., -8.3798, -7.9336, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -9.1748, -11.1537,   5.6441,  ..., -10.4314,  -9.8925, -11.4797]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.1153, -10.5524,   5.1333,  ...,  -8.3677, -10.0384, -10.5396]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.6871, -11.1059,   3.9026,  ...,  -9.1898, -11.2648, -10.6690]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.7615,  -9.8794,   7.1102,  ...,  -9.7695, -11.1792, -10.5014]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -7.5902, -10.1332,   4.8415,  ...,  -9.3391,  -9.4361,  -9.9072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ -8.3825, -10.3479,   8.6518,  ...,  -9.2627, -10.1946, -10.4224]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kitchen',\n",
       " 'sits',\n",
       " 'a',\n",
       " 'table',\n",
       " 'above',\n",
       " 'with',\n",
       " '<end>']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.evaluate(im, cap, True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
